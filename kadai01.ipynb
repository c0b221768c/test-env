{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import tqdm\n",
    "import copy\n",
    "import torchvision.models as models\n",
    "from icecream import ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataManager(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        super(MyDataManager, self).__init__()\n",
    "        with open(root, \"r\") as f:\n",
    "            self.image_list = f.read().splitlines()\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.image_list[idx])\n",
    "        label_split = self.image_list[idx].split(\"/\")[-2]\n",
    "        label = int(label_split.split(\"_\")[-2])\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return transforms.ToTensor()(img), label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"train.txt\"\n",
    "val_path = \"val.txt\"\n",
    "judge_path = \"real\"\n",
    "\n",
    "train_data = MyDataManager(train_path)\n",
    "train_dataLoader = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_data = MyDataManager(val_path)\n",
    "val_dataLoader = DataLoader(val_data, batch_size=8, shuffle=True, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_make(weight):\n",
    "    net = models.resnet50(weights=weight)\n",
    "    net.fc = nn.Linear(2048, 1024)\n",
    "    net.fc = nn.Sequential(\n",
    "        net.fc,\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(1024, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(256, 1),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "    ic(net)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"ResNet_weight.pth\"\n",
    "text_name = \"ResNet.txt\"\n",
    "\n",
    "epochs = 3\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "net = net_make(models.ResNet50_Weights.IMAGENET1K_V2).to(device)\n",
    "criterion = nn.BCELoss().to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
    "\n",
    "best_acc = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    accuracy_train = 0.0\n",
    "    total_num = 0.0\n",
    "    net.train()\n",
    "\n",
    "    for i, (imgs, labels) in tqdm.tqdm(enumerate(train_dataLoader), total=len(train_dataLoader)):\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device=device, dtype=torch.float32)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(imgs)\n",
    "        loss = criterion(outputs, torch.reshape(labels, (labels.shape[0], 1)))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()*labels.shape[0]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs[torch.where(outputs >= 0.5)] = 1\n",
    "            outputs[torch.where(outputs < 0.5)] = 0\n",
    "            labels = torch.reshape(labels, (labels.shape[0], 1))\n",
    "            accuracy_train += torch.sum(outputs == labels).item()\n",
    "            total_num += labels.shape[0]\n",
    "\n",
    "        if i % 10 == 9:\n",
    "            ic(f\"epoch:{epoch+1}, iter:{i+1}, loss:{running_loss/total_num:.5f}, accuracy(train) = {accuracy_train/total_num*100:.3f}%\")\n",
    "    \n",
    "    net.eval()\n",
    "    total_num = 0.0\n",
    "    accuracy_val = 0.0\n",
    "    for imgs, labels in val_dataLoader:\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device=device, dtype=torch.float32)\n",
    "        with torch.no_grad():\n",
    "            outputs = net(imgs)\n",
    "            outputs[torch.where(outputs >= 0.5)] = 1\n",
    "            outputs[torch.where(outputs < 0.5)] = 0\n",
    "            labels = torch.reshape(labels, (labels.shape[0], 1))\n",
    "            accuracy_val += torch.sum(outputs == labels).item()\n",
    "            total_num += labels.shape[0]\n",
    "    epoch_acc = accuracy_val/total_num\n",
    "    ic(f\"accuracy(valid) = {epoch_acc*100:.3f}%\")\n",
    "    with open(text_name, mode=\"a\") as f:\n",
    "        f.write(f\"accuracy(valid) = {epoch_acc*100:.3f}%\\n\")\n",
    "    \n",
    "    if epoch_acc > best_acc:\n",
    "        best_acc = epoch_acc\n",
    "        best_model_wts = copy.deepcopy(net.state_dict())\n",
    "        torch.save(best_model_wts, save_path)\n",
    "ic(f\"best_accuracy = {best_acc*100:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"test.txt\"\n",
    "weight = \"ResNet_weight.pth\"\n",
    "\n",
    "test_data = MyDataManager(test_path)\n",
    "test_dataLoader = DataLoader(test_data, batch_size=8, shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "net = net_make(weight).to(device)\n",
    "net.load_state_dict(torch.load(weight, weights_only=True))\n",
    "net.eval()\n",
    "\n",
    "total_num = 0\n",
    "accuracy_test = 0.0\n",
    "for imgs, labels in tqdm.tqdm(test_dataLoader):\n",
    "    imgs = imgs.to(device)\n",
    "    labels = labels.to(device=device, dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "        outputs = net(imgs)\n",
    "        outputs[torch.where(outputs >= 0.5)] = 1\n",
    "        outputs[torch.where(outputs < 0.5)] = 0\n",
    "        labels = torch.reshape(labels, (labels.shape[0], 1))\n",
    "        accuracy_test += torch.sum(outputs == labels).item()\n",
    "        total_num += labels.shape[0]\n",
    "ic(f\"accuracy(test) = {accuracy_test/total_num*100:.3f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
