{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import tqdm\n",
    "import copy\n",
    "import torchvision.models as models\n",
    "import io\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataManager(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        super(MyDataManager, self).__init__()\n",
    "        with open(root, \"r\") as f:\n",
    "            self.image_list = f.read().splitlines()\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.image_list[idx])\n",
    "        label_split = self.image_list[idx].split(\"/\")[-2]\n",
    "        label = int(label_split.split(\"_\")[-2])\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return transforms.ToTensor()(img), label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JPEGCompressionTransform:\n",
    "    def __init__(self, quality=55):\n",
    "        self.quality = quality\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        buffer = io.BytesIO()\n",
    "        img.save(buffer, format=\"JPEG\", quality=self.quality)\n",
    "        buffer.seek(0)\n",
    "        compressed_img = Image.open(buffer)\n",
    "        return compressed_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_make(weight):\n",
    "    net = models.resnet50(weight=weight)\n",
    "    net.fc = torch.Linear(2048, 1024)\n",
    "    net.fc = nn.Sequential(\n",
    "        net.fc,\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(1024, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(256, 1),\n",
    "        nn.Sigmoid(),\n",
    "    )\n",
    "    print(net)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"test.txt\"\n",
    "weight = \"ResNet_weight.pth\"\n",
    "\n",
    "transform = transforms.Compose([JPEGCompressionTransform(quality=95)])\n",
    "test_data = MyDataManager(test_path, transform=transform)\n",
    "test_dataLoader = DataLoader(test_data, batch_size=8, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "net = net_make(None).to(device)\n",
    "net.load_state_dict(torch.load(weight, weight_only=True))\n",
    "net.eval()\n",
    "\n",
    "total_num = 0\n",
    "accuracy_test = 0.0\n",
    "for imgs, labels in tqdm.tqdm(test_dataLoader):\n",
    "    imgs = imgs.to(device)\n",
    "    labels = labels.to(device=device, dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "        outputs = net(imgs)\n",
    "        outputs[torch.where(outputs >= 0.5)] = 1\n",
    "        outputs[torch.where(outputs < 0.5)] = 0\n",
    "        labels = torch.reshape(labels, (labels.shape[0], 1))\n",
    "        accuracy_test += torch.sum(outputs == labels).item()\n",
    "        total_num += imgs.shape[0]\n",
    "print(f\"accuracy(test) = {accuracy_test/total_num*100:.3f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
